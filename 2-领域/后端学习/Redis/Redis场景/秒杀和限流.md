---
Created: 2024-01-17
Updated: 2024-01-17
Type: knowledge
Status: ⌛️ 等待
截止日期: 
目标: 
领域: 
tags:
---
- [x] 秒杀场景、和限流场景记得补充，已完成，限流场景详见[[请求限流的方式]] ✅ 2024-06-24
## 秒杀场景

秒杀场景对于大众来说都比较耳熟能详，但是具体怎么实现还是要研究一下的

首先有几个注意的点
1. @ 海量的请求，要能抗住，对服务器有要求
2. @ 不能超卖，分布式场景下，要保证数据的最大值
3. @ 避免少卖
4. @ 防止黄牛

那我们就一个个分析

### 海量请求高并发怎么解决？

主要思路在于，削峰，限流，异步，补偿
请求太多，不可能直接打到 mysql 或者其他数据库上，那么很简单，就是利用 redis 去计算名额，**redis 单机支持每秒几万的写入**甚至还能做集群，提高扩展能力

请求进来先去 redis 里面算名额，然后进消息队列，最后慢慢由服务消费掉

### 不能超卖

我们利用的 redis 做的名额计算，那么我们就能通过 lua 脚本来保证原子性，即查询库存，扣减库存作为一个原子服务，每个请求进来都是单线程的扣减，保证了原子性

### 不能少卖
我们上面讲的流程可以如图
![image.png](https://obsidian-pic-1317906728.cos.ap-nanjing.myqcloud.com/obsidian/20240624234420.png)

1，2 两部分走完之后（12 步视为一个原子服务）再去发消息给卡夫卡，但是这里可能会出现问题：
1. ~ redis 请求超时
2. ~ Redis 操作成功了，但是往 kafuka 发消息失败了
这些都会导致 **redis 里面的名额被消费了，但是实际上并没有通过 kafuka 生成订单**

针对第一点，redis 请求超时的话，可能是 redis 不够多，可以做一个 redis 的集群，或者用 nginx 做一个负载均衡，整他 20 个redis
第二点的话，我们可以做一个渐进式的重试，比如发送卡夫卡消息失败，我们慢慢的做几次重试，到一定次数就不重试，也可以直接把失败数据写到磁盘上，后续慢慢重试